---
title: 你对下一代Transformer架构的预测是什么？
url: https://www.zhihu.com/question/1904728228213548260/answer/1975169767355736614
author: CodeCrafter
author_badge: 一个朴实的技术人
created: 2025-11-21 11:52
modified: 2025-11-21 11:52
upvote_num: 1878
comment_num: 56
---
未来五年的Transformer不会死，但它会变得面目全非。它将从一个纯粹的注意力机制堆叠，演变成一个巨大的、稀疏的、混合了循环状态空间模型（SSM）特性的“缝合怪”。我们现在看到的GPT-5或者Claude 4.5其实已经有了这个端倪。

站在2025年的尾巴上往回看，这几年挺有意思。2023年、2024年的时候，学术界每隔两周就要跳出来一个所谓的Transformer Killer，什么Mamba，什么RWKV，什么RetNet，声势浩大。结果呢？到了今天，生产环境里的主力还是Transformer。

为什么？因为生态。

但这不代表Transformer还是原来那个Transformer。Google当年的那篇《Attention Is All You Need》现在看简直就是个复古文件。我这两年在做大模型落地的时候，最明显的感受就是：纯Attention架构在大长文本（Long Context）场景下的算力损耗已经让人没法忍了。

我们要聊下一代架构，必须得先承认现在架构的痛点。

**痛点一：KV Cache显存爆炸。** 
你现在跑一个1M长度的上下文，如果还是全注意力机制，光是KV Cache就能把你的H100集群吃干抹净。所以下一代架构的第一个特征必然是：**去线性化注意力的全面普及与混合架构的常态化。** 

现在的趋势已经很明显了，像Jamba这样的架构，把Mamba（SSM）层和Transformer层混着搭。为什么这么干？因为SSM在推理时候是O(1)的显存占用，它不需要存那个该死的KV Cache。但是SSM有个毛病，就是“遗忘”。你让它去回忆两万字之前的一个具体人名，它可能给你产生幻觉。而Attention机制，虽然贵，但是它那个Look-up table的特性，让它拥有精准的“查字典”能力。

所以我大胆预测，五年后的Transformer，或者说那个时候的主流架构，**底层80%的层将会是线性复杂度模型（类似改进版的Mamba或RWKV），用来处理海量的背景信息和上下文维持；只有顶层或者关键节点的20%是全注意力层，专门用来做精准召回和强逻辑推演。** 

这就像什么呢，你大脑里大部分时候是潜意识在跑（SSM），只有遇到难题需要专注的时候，才调动前额叶去深度思考（Attention）。

这里推荐大家去硬啃一下Tri Dao大佬的FlashAttention系列论文，以及Mamba的原始论文。哪怕你是做产品的，也得看，看不懂公式看结论。只有懂了底层的IO瓶颈，你才知道为什么模型推理成本降不下来。


**痛点二：稠密计算的不可持续性。** 
MoE（混合专家模型）在2024年彻底火了，现在2025年，谁家不出MoE谁就是落伍。但是现在的MoE还是很粗糙。现在的MoE大部分是基于Token级别的路由，一个Token过来，选两个专家算一下。

下一代的Transformer，**稀疏化（Sparsity）会进入到更细的粒度。**  现在的MoE是“大块头”专家，以后会出现“神经元级别”的动态激活。可能会出现一种架构，它不再有明确的FFN层和Attention层的界限，整个网络就是一个巨大的动态路由图。

我看过DeepMind那边的一些探索，虽然还没彻底铺开，但那个方向是对的。就是让计算量不再和参数量强绑定，也不再和Token数量呈简单的线性关系。**模型会学会“偷懒”。**  遇到简单的Token，比如“的”、“了”这种停用词，它可能一层都不跑，直接透传；遇到复杂的逻辑推理题，它会在内部循环思考好几轮再输出。

这就引出了我的第三个预测。

### System 2 的架构化：Thinking Process 融入骨髓

OpenAI的o1系列在2024年给了行业一点小小的震撼。那时候大家还在卷预训练数据，它突然告诉你，推理时的强化学习（RL）可以让模型产生“慢思考”。

现在的Transformer架构，本质上还是一个System 1模型——直觉反应。它预测下一个字，是基于概率的条件反射。o1这种所谓的System 2，目前更多是在数据构造和推理流程上做的文章（CoT），而不是架构本身的改变。

**五年后的Transformer，会在架构层面原生支持System 2。** 

现在的CoT，是把思考过程打印在Context里，这很浪费。你为了算一道数学题，输出了几千个Token的中间步骤，这些Token都得占显存，还得走一遍解码。

下一代架构可能会引入一种**隐式状态空间（Latent State Space）的循环机制** 。模型可以在内部的一个Latent Space里“空转”很多轮，在这个高维空间里推演、回溯、纠错，直到它觉得满意了，再把结果映射回文字Token输出出来。

这意味着Transformer可能会长出“海马体”和“工作记忆区”。它不再是纯粹的前馈网络（Feed Forward），它会有明确的Recurrent结构，但不是为了处理序列，而是为了处理“思考的时间步”。

如果你对这个方向感兴趣，建议去追一下Yann LeCun一直在推的JEPA架构，虽然他骂了Transformer好几年，但JEPA里关于World Model和预测潜在表征的思想，绝对会被整合进下一代的Transformer里。

*资源推荐：去读Yann LeCun的那篇 `A Path Towards Autonomous Machine Intelligence`。虽然有点哲学味，但那是未来架构的蓝图。*

### 多模态的原生融合：Tokenizer的消亡

到了2025年，如果你还在分别训练一个Vision Encoder和一个Text Decoder，然后中间用个Projector连起来，那你真的太Old School了。

现在的多模态模型，大部分还是“拼凑”的。图像被切成Patch，变成Token；音频被切成Frame，变成Token。这种做法有个大问题：**信息损失。**  把连续的像素信号强行离散化成Token，本身就是一种有损压缩。

下一代的Transformer，或者说接替者，**将不再依赖离散的Tokenizer。** 

Meta前两年搞的ImageBind虽然是个雏形，但还没做到头。未来的模型输入端，将直接处理原始信号（Raw Signal）。这需要架构层面支持连续值的输入处理。可能是基于扩散模型（Diffusion）的反向过程来做理解，或者是某种新型的神经拟态架构。

在这个阶段，**文本（Text）将不再是核心。**  现在的LLM，是以文本为中心的，图像和声音都是“附庸”。五年后，模型的核心表征将是**世界模型（World Model）的物理表征** ，文本只是这个表征的一种输出接口而已。

这带来的工程挑战是巨大的。我们现有的所有训练框架，Megatron-LM也好，DeepSpeed也好，都是为了离散Token优化的。要改这个，等于要把地基挖了重填。但这是必须要走的路，因为只靠文本数据，模型永远学不会真正的物理规律。

这里分享一个真实的教训。我们团队之前试图用纯文本数据去微调一个写代码的模型，让它控制机械臂。结果代码写得极好，逻辑完美，但一上机就撞墙。为什么？因为模型不懂重力，不懂摩擦力，它只是在模仿代码的统计规律。后来我们引入了传感器数据的直接Embedding，效果才上去。所以，多模态原生是必经之路。

### 硬件倒逼架构：Matrix Multiplication (MatMul) 的统治与反叛

聊架构不聊硬件就是耍流氓。

Transformer之所以能赢，很大程度上是因为它完美契合了GPU的设计。GPU最擅长算什么？矩阵乘法（MatMul）。Transformer里全是MatMul。

但是，MatMul正变得越来越昂贵。不是钱的问题，是能耗的问题。人脑的能耗是20瓦，H100集群的能耗是核电站级别。

五年后的架构，会尝试**摆脱对MatMul的绝对依赖。** 

虽然现在的BitNet（1-bit LLM）看起来还很初级，甚至有点像玩具，但它揭示了一个方向：**量化不应该只是部署时的优化手段，而应该是架构设计的一部分。** 

未来的Transformer，可能在训练的时候就是INT4甚至INT1的。这意味着架构内部的激活函数、归一化层（LayerNorm/RMSNorm）全都要改。现在的LayerNorm在低精度下极不稳定，经常梯度爆炸。下一代架构会发明出专门适应低精度计算的“粗糙”组件。

而且，随着存内计算（Processing-in-Memory, PIM）的发展，架构会变得更加**本地化** 。现在的Transformer每一层都要把整个Hidden State搬来搬去，带宽瓶颈卡死人。未来的架构可能会更像大脑皮层，计算是局部的，只有少量的长程连接。这跟前面说的稀疏化MoE其实是异曲同工。

说了这么多预测，其实我想表达的核心观点是：**Transformer不是终点，它只是一个过渡态。** 

如果你是做算法的同学，千万别把自己的技能树全点在“调Transformer超参”上。现在不管是RoPE的位置编码变体，还是各种魔改的Attention Mask，过几年可能全都没用了。

你应该关注的是更本质的东西：

1. **信息论与压缩** ：模型本质上是在做压缩。不管架构怎么变，压缩率（Perplexity）是不变的指标。
2. **优化理论** ：SGD和AdamW统治了太久，有没有针对稀疏架构的更好优化器？
3. **数据工程** ：这才是真正的护城河。架构开源得很快，但处理数据的Recipe（配方）各家都捂得死死的。

以后可能我们都不再称呼它为“Transformer”了。它可能叫“通用状态机”或者“神经推理引擎”。但它的魂还在：**基于梯度下降的端到端学习。** 

虽然大家都在喊AGI，但目前的Transformer架构，本质上还是在做概率拟合。它没有真正的“创造力”，它的创造只是在巨大的样本空间里做插值。

下一代的架构，如果想要突破，必须引入**非连续的、符号化的逻辑推理模块** 。这可能不是纯神经网络能搞定的，也许是Neuro-Symbolic AI（神经符号主义）的文艺复兴。

如果你现在手头有卡，别光跑SFT（监督微调）了。试着去复现一下那些非Transformer的架构，试着把SSM插进Transformer里，试着把Embedding层换成连续信号输入。那些在今天看起来“离经叛道”或者“效果不佳”的尝试，往往就是五年后教科书里的标准答案。

这个行业变化太快，快到我写这段话的时候，DeepSeek或者OpenAI可能又发了一篇新Paper，把我的脸打肿。但那又怎样呢？这正是我们这帮搞技术的人，最兴奋的时代。保持饥饿，保持愚蠢，别信权威，连我上面说的这些，你也别全信，去跑代码，去炸显存，去看着Loss曲线发呆，那才是真实的未来。



---

## 评论

共 56 条评论，已存 12 条

### 亚洲牧二凤

这篇文章最后一段话 太疯狂 太极客了 看得我热血沸腾

2025-11-21 浙江 43 赞

### 杨TechTips

看看近处的RWKV8 Rosa吧，家人们。

2025-11-21 云南 23 赞

> #### Kfeimeo
> 
> 是的，这是少见的神经符号主义
> 
> 2025-11-21 广东 2 赞

### bestwang

实际上，moe不是新东西，google 4年前就用上了，而现在各种sparse attention， liner attention 效果都不好。deepseek 3.2 的sparse attention 效果都看到了，minimax 之前用hybrid ，结果最新模型又退回full attention。 对现在高要求，长时间运行的agentic coding等任务，各种新模型结构的缺陷显而易见。中国算力不足，喜欢搞模型结构，为了节省算力，美国主打力大转飞，scale up 数据和rl, 推进智能上限，效率主要是靠强大的infra团队优化。 中国团队，基本上目标是用尽可能少的算了去接近效果，但各种节约算力的结构怎么可能没有折损。国模在各种评测集上分数看起来不错，包括各种模型结构创新，分数好像能打平传统结构, 但实际在生成环境下，实际效果怎么样，大家用过的也应该清楚。

2025-11-21 北京 22 赞

### 王老五

写的好，大部分观点和你一致，现在的和过去变形金刚的架构不是本质。但不觉得以后的agi的架构会是设计出来的，而是在大量主动以及被动生成的数据下生长出来或者是搜索出来的。

2025-11-21 美国 7 赞

> #### Drozdovsky
> 
> 现在的架构就缺少生物大脑神经元的动态连接过程，这个不是仅靠稀疏权重矩阵就能模拟的
> 
> 2025-12-03 北京 1 赞

### 张慢慢

我曹，就为了最后一句话，顶上去

2025-11-21 安徽 4 赞

### 点点

moe的路由层一定程度上起到的就是海马体的功能 每个token跑完继续回去路由循环跑 只是粒度被限定在词语上了如果更细粒度 而这里也更动态 那恰好就是海马体与皮层稀疏循环的交互

2025-12-06 北京 2 赞

### Kfeimeo

你说到重点了，结合符号主义

2025-11-21 广东 3 赞

### 三日猫

也可以底层是因果卷积层[doge][好奇]。总之浅层应该是sparse连接的，深层可能才会用到dense来查询。

2025-11-27 浙江 1 赞

### 凤凰之翼王萧

兄弟专业呀！

2025-11-21 浙江 1 赞

### SaviorZ

大佬[拜托]

2025-11-21 广东 2 赞
