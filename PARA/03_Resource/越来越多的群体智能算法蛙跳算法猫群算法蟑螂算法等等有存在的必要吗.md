---
创建时间: 2026-02-02
最后修改: 2026-02-15
状态:
  - Resource
tags: []
para: resource
aliases:
  - "越来越多的群体智能算法蛙跳算法猫群算法蟑螂算法等等有存在的必要吗_0330"
---
# 越来越多的群体智能算法（蛙跳算法、猫群算法、蟑螂算法等等）有存在的必要吗？
[内容链接](https://www.zhihu.com/question/22752108/answer/2997836686)

完了，现在玩优化理论的变得跟玩控制理论的一个味儿了，动不动就“XXXX类算法有必要存在吗”。优化算法实战派们看到这个问题估计要直接掀桌子了。你例举的这些算法，无论是传统的演进算法还是五花八门的群体智能算法，在实战派眼里统称derivative-free优化算法（中文不知怎么翻译，此文暂且统称为“无需求导的优化算法”）。这类算法在庞大的制造业领域当中千奇百怪的细分应用场景里有着他们特有的用户群体和应用市场，因此在这类算法身上进行任何形式的深耕细作都是完全有必要的。

优化理论派都有个特点，凡事讲究个所以然，全局最优解不但每次要稳稳地找到，寻找的过程还必须得优雅。理论派在思维模式上一般都是在现有的优化理论框架基础上萌生出新算法的idea，然后以发挥新算法最大优势为目的去挑选问题案例并设计相应的数学模型。理论派的这些模型一般都是他们自己用编程代码从头写的，因此整个模型的求导信息完全透明，矩阵计算并行化处理也简单，这样的话他们自然也就对那些既无需求导又支持并行计算但难以从传统优化理论上解释清楚的演进算法和群体智能算法感到不屑一顾了。

然而实战派跟理论派相比有两个最大不同点：

（1）**实战派所用的模型是要跟真实物理世界打交道的，是要用来解决真实物理世界的实际优化问题的，而不是理论派们为了证明自己算法的优越性而特别设计的toy model。**真实的物理模型都是极其复杂的跨尺度机理模型，动辄包含几十万、几百万个变量和非线性方程，这在日费千金的真实工程项目场景中靠自己码代码从头写是不现实的，因此这些模型往往都需要依靠各类工业软件中提供的现成模型库、参数库和算法库去自选搭建才能在合理时间内开发出来。但这里的问题是，工业软件为了降低维护成本和复杂度，都是依照模块思维设计的，也就是说求解一个软件里的模型的过程当中先开始算哪个子模型、后算哪个子模型，其计算顺序都是由第三方软件开发团队给严格“焊死”了的，这就让用户无法直接获得模型的完整导数信息。在这种求导信息不透明的计算场景下，原问题里说的那些在理论派眼里相当于玄学的演进算法（遗传算法、差分演进算法）、群体智能算法（蚁群、粒子群算法）以及其他无需求导的优化算法（Nelder Mead etc.）就成了唯一可以依靠的工具。

（2）**真实项目场景中的问题往往规模很大，而且牵扯到的技术领域范围甚广，因此实战派们日常所用的模型里的各种子模型往往会来自不同的合作企业。**由于每个企业都有自己的软件文化和使用习惯，这些子模型很可能彼此都是在不同软件环境下开发，然后通过操作系统底层提供的微软组件对象模块（Win32 COM）和软件接口协议API来相互传递数据信息，从而让子模型之间能够进行互动沟通，以此组建成的大模型的数学求导信息自然也就无迹可寻了。更棘手的情况是，大多数时候第三方合作企业或机构会出于专利保护的目的，把交付出来的子模型文件都事先进行加密，外部人士使用时只有输入变量数据和读取计算输出结果的权限，而对于模型、参数、算法信息完全不可访问。因此，实战派在给所有这一类由不同企业合作方共同搭建出的大模型进行全局优化时，演进算法和群体智能算法由于它们的无需求导又支持并行化处理的独特优势，怕是唯一可以依赖的优化算法工具了。就连上面提到的Nelder Mead也不行，因为Nelder Mead虽然同样无需求导信息但并不支持并行计算（因为它每步迭代方向要取决于前两个迭代步的信息）。**毕竟在如今这个遍地廉价云计算资源的年代，支持并行计算即是正义。**

当然，除了无需求导的优化算法以外，上述的这两种真实问题场景也可以用代理建模技术（surrogate modeling）来解决，虽然是题外话但也是很有意思的领域方向。这种方法简单说就是用各种随机取样策略让无法求导的机理模型跑出最少但足够的输入输出相互映射的数据集，然后用数学结构更简单的代理模型架构对这些跑出来的输入输出数据集进行拟合。因为这么做能够直接把原模型的数学复杂度降低几个量级，所以这类方法也叫降次建模技术（reduced order modeling），这也是近些年开始重新兴起的新方向。只不过此类方法大多有两个缺点：一是由于模型的简化替换操作会引入额外的数值误差，二是在优化变量过多的情况下随机取样的数据量占整个取样空间的比例会呈指数级减小，这也就陷入了设计工程师们口中通常所说的维度诅咒（Curse of dimensionality）。我所知道的能够解决这两种问题的此类最前沿的算法是原CMU（现佐治亚理工）教授Nick Sahinidish创立的自适应学习式代理建模算法ALAMO（Automated Learning of Algebraic MOdels）。五年前我曾在前东家工作时有幸与尚在CMU的Sahinidish教授合作，并根据他本人的指点亲身使用过他的ALAMO算法来同时优化八个变量的能源技术方面的机理模型。这个机理模型在软件里单独模拟运行一次大概花5-10分钟，所以显然在单机上直接用群体智能算法优化就很要命了。我记忆印象里ALAMO算法是取样建模和迭代优化两者同时进行，而不是先建模后迭代优化。而且ALAMO识别出简单平缓表面并在取样时快速跳过，也可以把复杂陡峭表面自动识别出来并集中火力取样，然后根据局部取样信息一边建立局部代理模型一边用建好的代理模型进行迭代寻找暂时最优解，直到最终找到全局最优解为止，这样一来原本用群体智能算法需要十几个小时的优化问题一下子被缩减到一小时不到，效果还和前者相当，因此这也是我迄今为止用过的最先进的代理模型算法。
